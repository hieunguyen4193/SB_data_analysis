{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import os\n",
    "import anndata2ri\n",
    "import pathlib\n",
    "from scipy import io\n",
    "import anndata#\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import sys\n",
    "import re\n",
    "import scvelo as scv\n",
    "\n",
    "# Activate the anndata2ri conversion between SingleCellExperiment and AnnData\n",
    "# anndata2ri.activate()\n",
    "\n",
    "#Loading the rpy2 extension enables cell magic to be used\n",
    "#This runs R code in jupyter notebook cells\n",
    "# %load_ext rpy2.ipython\n",
    "\n",
    "sc.settings.verbosity = 3\n",
    "# sc.logging.print_versions()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "outdir = \"/media/hieunguyen/HD01/outdir/CRC1382/SBharadwaj_20250102\"\n",
    "\n",
    "path_to_main_src = \"/home/hieunguyen/CRC1382/src_2023/SBharadwaj/release\"\n",
    "samplesheet = pd.read_csv(os.path.join(path_to_main_src, \"SampleSheet_all_seurat_objects.csv\"))\n",
    "samplesheet[\"dataset_name\"] = samplesheet.apply(\n",
    "    lambda row: f\"{row['dataset_name']}_reIntegration\" if row[\"reIntegration\"] == \"yes\" else row[\"dataset_name\"],\n",
    "    axis=1\n",
    ")\n",
    "samplesheet = samplesheet.fillna(\"\")\n",
    "\n",
    "#####------------------------------------------------------------#####\n",
    "##### READ LOOM DATA\n",
    "#####------------------------------------------------------------#####\n",
    "path_to_loom_data = f\"{outdir}/loom\"\n",
    "all_looms = [item for item in pathlib.Path(path_to_loom_data).glob(\"*.loom\")]\n",
    "\n",
    "velodata_dict = dict()\n",
    "for input_loom in tqdm(all_looms):\n",
    "    velodata = scv.read_loom(input_loom)\n",
    "    samplename = input_loom.name.replace(\".loom\", \"\")\n",
    "\n",
    "    new_obs = [\"{}_{}_{}-1\".format(samplename, samplename, item.split(\":\")[1].replace(\"x\", \"\")) for item in velodata.obs.index]\n",
    "    velodata.obs.index = new_obs\n",
    "    velodata.obs[\"barcode\"] = new_obs\n",
    "    velodata.var_names_make_unique()\n",
    "    pattern = re.compile('_[A|T|G|C]*-')\n",
    "    new_obs = [samplename + pattern.search(string = item).group() + item.split(\"-\")[1]\n",
    "            for item in velodata.obs.index]\n",
    "    velodata.obs.index = new_obs\n",
    "    velodata_dict[samplename] = velodata\n",
    "    velodata.var_names_make_unique()\n",
    "\n",
    "all_velodata = velodata_dict[list(velodata_dict.keys())[0]]\n",
    "for data in list(velodata_dict.keys())[1:]:\n",
    "    all_velodata = all_velodata.concatenate(velodata_dict[data])\n",
    "    \n",
    "new_obs = [item.split(\"-\")[0] + \"-1\" for item in all_velodata.obs.index]\n",
    "all_velodata.obs.index = new_obs\n",
    "all_velodata.var_names_make_unique()\n",
    "\n",
    "#####------------------------------------------------------------#####\n",
    "##### MAIN FUNCTION\n",
    "#####------------------------------------------------------------#####\n",
    "for index, row in samplesheet.iterrows():\n",
    "    PROJECT = row['PROJECT']\n",
    "    dataset_name = row['dataset_name']\n",
    "    path_to_s_obj = row['path']\n",
    "    re_integration = row['reIntegration']\n",
    "    \n",
    "    re_integration = row['reIntegration']\n",
    "    if dataset_name == \"full\":\n",
    "        if re_integration in [\"yes\", \"\"]:\n",
    "            to_run_clusters = [\"cca.cluster.0.5\", \"cell.annotation\"]\n",
    "            reduction_name = \"cca_UMAP\"\n",
    "        else:\n",
    "            to_run_clusters = [\"seurat_clusters\", \"cell.annotation\"]\n",
    "            reduction_name = \"SCT_UMAP\"\n",
    "    else:\n",
    "        if re_integration in [\"yes\", \"\"]:\n",
    "            to_run_clusters = [\"cca.cluster.0.5\"]\n",
    "            reduction_name = \"cca_UMAP\"\n",
    "        else:\n",
    "            to_run_clusters = [\"seurat_clusters\"]\n",
    "            reduction_name = \"SCT_UMAP\"\n",
    "    \n",
    "    path_to_s_obj = path_to_s_obj.replace(\".rds\", \".addedInfo.rds\")\n",
    "    \n",
    "    path_to_main_output = os.path.join(outdir, PROJECT, \"data_analysis\")\n",
    "    path_to_08_output = os.path.join(path_to_main_output, \"08_output\", dataset_name)\n",
    "    os.makedirs(path_to_08_output, exist_ok=True)\n",
    "    \n",
    "    path_to_seurat2anndata = os.path.join(path_to_08_output, \"seurat2anndata\")\n",
    "    os.makedirs(path_to_seurat2anndata, exist_ok=True)\n",
    "\n",
    "    if PROJECT == \"SBharadwaj_20240318_Sample_3_6\":\n",
    "        to_run_clusters = [cluster for cluster in to_run_clusters if cluster != \"cell.annotation\"]\n",
    "    \n",
    "    for cluster_name in to_run_clusters:\n",
    "        object_name = f\"{PROJECT}_{dataset_name}_{cluster_name}\"\n",
    "\n",
    "        adata = sc.read_h5ad(os.path.join(path_to_seurat2anndata, '{}.h5ad'.format(object_name)))\n",
    "        obsdf = adata.obs.copy()\n",
    "        obsdf[\"barcode\"] = obsdf[[\"barcode\", \"name\"]].apply(lambda x: x[0].replace(f\"{x[1]}_{x[1]}\", f\"{x[1]}\"), axis = 1) \n",
    "        adata.obs.index = obsdf.barcode.values\n",
    "        adata.var_names_make_unique()\n",
    "\n",
    "        colordf = pd.read_csv(os.path.join(path_to_seurat2anndata, 'colordf_{}.csv'.format(object_name)))\n",
    "        colors = colordf[\"color\"].values\n",
    "        \n",
    "        #####------------------------------------------------------------#####\n",
    "        ##### Data pre-processing\n",
    "        #####------------------------------------------------------------#####\n",
    "        merge_data = scv.utils.merge(adata, all_velodata)\n",
    "        assert merge_data.obs.shape[0] == adata.obs.shape[0]\n",
    "        #####------------------------------------------------------------#####\n",
    "        ##### Merge data and preprocessing again\n",
    "        #####------------------------------------------------------------#####\n",
    "        scv.pp.filter_genes(merge_data, min_shared_counts=20)\n",
    "        scv.pp.normalize_per_cell(merge_data)\n",
    "        scv.pp.filter_genes_dispersion(merge_data, n_top_genes=2000)\n",
    "        scv.pp.log1p(merge_data)\n",
    "\n",
    "        scv.pp.filter_and_normalize(merge_data, min_shared_counts=20, n_top_genes=2000)\n",
    "        scv.pp.moments(merge_data, n_pcs=30, n_neighbors=30)\n",
    "\n",
    "        #####------------------------------------------------------------#####\n",
    "        ##### RNA velocity inference\n",
    "        #####------------------------------------------------------------#####\n",
    "        scv.tl.velocity(merge_data)\n",
    "        scv.tl.velocity_graph(merge_data)\n",
    "\n",
    "        #####------------------------------------------------------------#####\n",
    "        ##### save streamline RNA velocity\n",
    "        #####------------------------------------------------------------#####\n",
    "        scv.pl.velocity_embedding_stream(merge_data, \n",
    "                                        dpi=120, \n",
    "                                        arrow_size=2, basis = \"X_umap\",\n",
    "                                        color=\"cca.cluster.0.5\",\n",
    "                                figsize = (12, 12), \n",
    "                                fontsize=20, \n",
    "                                legend_fontsize = 30, \n",
    "                                frameon=True, \n",
    "                                save=\"streamline_{}.svg\".format(object_name),\n",
    "                                palette = colors)\n",
    "\n",
    "        ##### Gene ranking\n",
    "        scv.tl.rank_velocity_genes(merge_data, groupby=cluster_name, min_corr=.3)\n",
    "        df_gene_ranking = scv.DataFrame(merge_data.uns['rank_velocity_genes']['names'])\n",
    "        df_gene_ranking.to_excel(f\"./figures/{object_name}_gene_ranking.xlsx\")\n",
    "\n",
    "        ##### Pseudotime plot\n",
    "        scv.tl.velocity_pseudotime(merge_data)\n",
    "        scv.pl.scatter(merge_data, \n",
    "                    color='velocity_pseudotime', \n",
    "                    cmap='gnuplot', \n",
    "                    basis = \"X_umap\",\n",
    "                    figsize = (15, 15), \n",
    "                    fontsize=20, \n",
    "                    legend_fontsize = 30, \n",
    "                    frameon=True, \n",
    "                    save=\"pseudotime_{}.svg\".format(object_name),\n",
    "                    palette = colors)\n",
    "\n",
    "        ##### Speed and coherence\n",
    "        scv.tl.velocity_confidence(merge_data)\n",
    "        keys = 'velocity_length', 'velocity_confidence'\n",
    "        scv.pl.scatter(merge_data, c=keys, cmap='coolwarm', perc=[5, 95], basis = \"X_umap\", frameon=True, \n",
    "                    figsize = (10, 10), save=\"speed_coherence_{}.svg\".format(object_name))\n",
    "\n",
    "        df = merge_data.obs.groupby(cluster_name)[keys].mean().T\n",
    "        df.to_excel(f\"./figures/{object_name}_speed_coherence.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hieunguyen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
