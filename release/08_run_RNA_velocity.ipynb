{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m velodata_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_loom \u001b[38;5;129;01min\u001b[39;00m tqdm(all_looms):\n\u001b[0;32m---> 45\u001b[0m     velodata \u001b[38;5;241m=\u001b[39m \u001b[43mscv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_loom\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_loom\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     samplename \u001b[38;5;241m=\u001b[39m input_loom\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.loom\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m     new_obs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-1\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(samplename, samplename, item\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m velodata\u001b[38;5;241m.\u001b[39mobs\u001b[38;5;241m.\u001b[39mindex]\n",
      "File \u001b[0;32m~/miniconda3/envs/hieunguyen/lib/python3.10/site-packages/anndata/compat/__init__.py:305\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m    308\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args], args[\u001b[38;5;241m-\u001b[39mextra_args:])\n\u001b[1;32m    311\u001b[0m ]\n",
      "File \u001b[0;32m~/miniconda3/envs/hieunguyen/lib/python3.10/site-packages/anndata/_io/read.py:259\u001b[0m, in \u001b[0;36mread_loom\u001b[0;34m(filename, sparse, cleanup, X_name, obs_names, obsm_names, var_names, varm_names, dtype, obsm_mapping, varm_mapping, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m layers \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X_name \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    258\u001b[0m     layers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatrix\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 259\u001b[0m         \u001b[43mlc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mtocsr() \u001b[38;5;28;01mif\u001b[39;00m sparse \u001b[38;5;28;01melse\u001b[39;00m lc\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m][()]\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    260\u001b[0m     )\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m lc\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/hieunguyen/lib/python3.10/site-packages/loompy/loom_layer.py:123\u001b[0m, in \u001b[0;36mLoomLayer.sparse\u001b[0;34m(self, rows, cols)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m \tvals \u001b[38;5;241m=\u001b[39m view\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname][:, :]\n\u001b[0;32m--> 123\u001b[0m nonzeros \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m data\u001b[38;5;241m.\u001b[39mappend(vals[nonzeros])\n\u001b[1;32m    125\u001b[0m row\u001b[38;5;241m.\u001b[39mappend(nonzeros[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mwhere\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import os\n",
    "import anndata2ri\n",
    "import pathlib\n",
    "from scipy import io\n",
    "import anndata#\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import sys\n",
    "import re\n",
    "import scvelo as scv\n",
    "\n",
    "# Activate the anndata2ri conversion between SingleCellExperiment and AnnData\n",
    "# anndata2ri.activate()\n",
    "\n",
    "#Loading the rpy2 extension enables cell magic to be used\n",
    "#This runs R code in jupyter notebook cells\n",
    "# %load_ext rpy2.ipython\n",
    "\n",
    "sc.settings.verbosity = 3\n",
    "# sc.logging.print_versions()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "outdir = \"/media/hieunguyen/HD01/outdir/CRC1382/SBharadwaj_20250102\"\n",
    "\n",
    "path_to_main_src = \"/home/hieunguyen/CRC1382/src_2023/SBharadwaj/release\"\n",
    "samplesheet = pd.read_csv(os.path.join(path_to_main_src, \"SampleSheet_all_seurat_objects.csv\"))\n",
    "samplesheet[\"dataset_name\"] = samplesheet.apply(\n",
    "    lambda row: f\"{row['dataset_name']}_reIntegration\" if row[\"reIntegration\"] == \"yes\" else row[\"dataset_name\"],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "#####------------------------------------------------------------#####\n",
    "##### READ LOOM DATA\n",
    "#####------------------------------------------------------------#####\n",
    "path_to_loom_data = f\"{outdir}/loom\"\n",
    "all_looms = [item for item in pathlib.Path(path_to_loom_data).glob(\"*.loom\")]\n",
    "\n",
    "velodata_dict = dict()\n",
    "for input_loom in tqdm(all_looms):\n",
    "    velodata = scv.read_loom(input_loom)\n",
    "    samplename = input_loom.name.replace(\".loom\", \"\")\n",
    "\n",
    "    new_obs = [\"{}_{}_{}-1\".format(samplename, samplename, item.split(\":\")[1].replace(\"x\", \"\")) for item in velodata.obs.index]\n",
    "    velodata.obs.index = new_obs\n",
    "    velodata.obs[\"barcode\"] = new_obs\n",
    "    velodata.var_names_make_unique()\n",
    "    pattern = re.compile('_[A|T|G|C]*-')\n",
    "    new_obs = [samplename + pattern.search(string = item).group() + item.split(\"-\")[1]\n",
    "            for item in velodata.obs.index]\n",
    "    velodata.obs.index = new_obs\n",
    "    velodata_dict[samplename] = velodata\n",
    "    velodata.var_names_make_unique()\n",
    "\n",
    "all_velodata = velodata_dict[list(velodata_dict.keys())[0]]\n",
    "for data in list(velodata_dict.keys())[1:]:\n",
    "    all_velodata = all_velodata.concatenate(velodata_dict[data])\n",
    "    \n",
    "new_obs = [item.split(\"-\")[0] + \"-1\" for item in all_velodata.obs.index]\n",
    "all_velodata.obs.index = new_obs\n",
    "all_velodata.var_names_make_unique()\n",
    "\n",
    "#####------------------------------------------------------------#####\n",
    "##### MAIN FUNCTION\n",
    "#####------------------------------------------------------------#####\n",
    "for index, row in samplesheet.iterrows():\n",
    "    PROJECT = row['PROJECT']\n",
    "    dataset_name = row['dataset_name']\n",
    "    path_to_s_obj = row['path']\n",
    "    re_integration = row['reIntegration']\n",
    "    \n",
    "    if re_integration in [\"yes\", \"\"]:\n",
    "        reduction_name = \"cca_UMAP\"\n",
    "    else:\n",
    "        reduction_name = \"SCT_UMAP\"\n",
    "    \n",
    "    print(f\"Working on PROJECT {PROJECT}, dataset name {dataset_name}\")\n",
    "    \n",
    "    path_to_s_obj = path_to_s_obj.replace(\".rds\", \".addedInfo.rds\")\n",
    "    \n",
    "    path_to_main_output = os.path.join(outdir, PROJECT, \"data_analysis\")\n",
    "    path_to_08_output = os.path.join(path_to_main_output, \"08_output\", dataset_name)\n",
    "    os.makedirs(path_to_08_output, exist_ok=True)\n",
    "    \n",
    "    path_to_seurat2anndata = os.path.join(path_to_08_output, \"seurat2anndata\")\n",
    "    os.makedirs(path_to_seurat2anndata, exist_ok=True)\n",
    "\n",
    "    object_name = f\"{PROJECT}_{dataset_name}\"\n",
    "\n",
    "    adata = sc.read_h5ad(os.path.join(path_to_seurat2anndata, '{}.h5ad'.format(object_name)))\n",
    "    obsdf = adata.obs.copy()\n",
    "    obsdf[\"barcode\"] = obsdf[[\"barcode\", \"name\"]].apply(lambda x: x[0].replace(f\"{x[1]}_{x[1]}\", f\"{x[1]}\"), axis = 1) \n",
    "    adata.obs.index = obsdf.barcode.values\n",
    "    adata.var_names_make_unique()\n",
    "\n",
    "    colordf = pd.read_csv(os.path.join(path_to_seurat2anndata, 'colordf_{}.csv'.format(object_name)))\n",
    "    colors = colordf[\"color\"].values\n",
    "    \n",
    "    #####------------------------------------------------------------#####\n",
    "    ##### Data pre-processing\n",
    "    #####------------------------------------------------------------#####\n",
    "    merge_data = scv.utils.merge(adata, all_velodata)\n",
    "    assert merge_data.obs.shape[0] == adata.obs.shape[0]\n",
    "    #####------------------------------------------------------------#####\n",
    "    ##### Merge data and preprocessing again\n",
    "    #####------------------------------------------------------------#####\n",
    "    scv.pp.filter_genes(merge_data, min_shared_counts=20)\n",
    "    scv.pp.normalize_per_cell(merge_data)\n",
    "    scv.pp.filter_genes_dispersion(merge_data, n_top_genes=2000)\n",
    "    scv.pp.log1p(merge_data)\n",
    "\n",
    "    scv.pp.filter_and_normalize(merge_data, min_shared_counts=20, n_top_genes=2000)\n",
    "    scv.pp.moments(merge_data, n_pcs=30, n_neighbors=30)\n",
    "\n",
    "    #####------------------------------------------------------------#####\n",
    "    ##### RNA velocity inference\n",
    "    #####------------------------------------------------------------#####\n",
    "    scv.tl.velocity(merge_data)\n",
    "    scv.tl.velocity_graph(merge_data)\n",
    "\n",
    "    #####------------------------------------------------------------#####\n",
    "    ##### save streamline RNA velocity\n",
    "    #####------------------------------------------------------------#####\n",
    "    scv.pl.velocity_embedding_stream(merge_data, \n",
    "                                    dpi=120, \n",
    "                                    arrow_size=2, basis = \"X_umap\",\n",
    "                                    color=\"cca.cluster.0.5\",\n",
    "                            figsize = (12, 12), \n",
    "                            fontsize=20, \n",
    "                            legend_fontsize = 30, \n",
    "                            frameon=True, \n",
    "                            save=\"streamline_{}.svg\".format(object_name),\n",
    "                            palette = colors)\n",
    "\n",
    "    ##### Gene ranking\n",
    "    scv.tl.rank_velocity_genes(merge_data, groupby='cca.cluster.0.5', min_corr=.3)\n",
    "    df_gene_ranking = scv.DataFrame(merge_data.uns['rank_velocity_genes']['names'])\n",
    "    df_gene_ranking.to_excel(f\"./figures/{object_name}_gene_ranking.xlsx\")\n",
    "\n",
    "    ##### Pseudotime plot\n",
    "    scv.tl.velocity_pseudotime(merge_data)\n",
    "    scv.pl.scatter(merge_data, \n",
    "                   color='velocity_pseudotime', \n",
    "                   cmap='gnuplot', \n",
    "                   basis = \"X_umap\",\n",
    "                   figsize = (15, 15), \n",
    "                   fontsize=20, \n",
    "                   legend_fontsize = 30, \n",
    "                   frameon=True, \n",
    "                   save=\"pseudotime_{}.svg\".format(object_name),\n",
    "                   palette = colors)\n",
    "\n",
    "    ##### Speed and coherence\n",
    "    scv.tl.velocity_confidence(merge_data)\n",
    "    keys = 'velocity_length', 'velocity_confidence'\n",
    "    scv.pl.scatter(merge_data, c=keys, cmap='coolwarm', perc=[5, 95], basis = \"X_umap\", frameon=True, \n",
    "                figsize = (10, 10), save=\"speed_coherence_{}.svg\".format(object_name))\n",
    "\n",
    "    df = merge_data.obs.groupby('cca.cluster.0.5')[keys].mean().T\n",
    "    df.to_excel(f\"./figures/{object_name}_speed_coherence.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hieunguyen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
